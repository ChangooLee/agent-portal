# LiteLLM Configuration
# LLM Gateway 설정 - 다양한 모델을 통합 관리

model_list:
  # OpenAI Models
  - model_name: gpt-4
    litellm_params:
      model: gpt-4
      api_key: ${OPENAI_API_KEY}
  
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: gpt-3.5-turbo
      api_key: ${OPENAI_API_KEY}

  # Anthropic Claude
  - model_name: claude-3-opus
    litellm_params:
      model: claude-3-opus-20240229
      api_key: ${ANTHROPIC_API_KEY}
  
  - model_name: claude-3-sonnet
    litellm_params:
      model: claude-3-sonnet-20240229
      api_key: ${ANTHROPIC_API_KEY}

  # Open Source Models (vLLM 또는 Ollama)
  - model_name: llama-2-7b
    litellm_params:
      model: vllm/llama-2-7b-chat-hf
      api_base: ${VLLM_API_BASE:-http://vllm:8000/v1}

# General Settings
general_settings:
  # Langfuse Integration
  set_verbose: true
  success_callback: ["langfuse"]
  
  # Helicone Integration (via proxy)
  # Helicone는 HTTP 프록시로 설정 가능

# Langfuse Settings
litellm_settings:
  success_callback: ["langfuse"]
  failure_callback: []
  langfuse_public_key: ${LANGFUSE_PUBLIC_KEY}
  langfuse_secret_key: ${LANGFUSE_SECRET_KEY}
  langfuse_host: ${LANGFUSE_HOST:-http://langfuse:3000}
  use_client: true

# Rate Limiting
router_settings:
  enable_pre_call_checks: true
  allowed_fails: 2

# Cost Tracking
cost_tracking:
  enabled: true


