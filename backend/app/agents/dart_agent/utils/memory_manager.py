"""
memory_manager.py
DART ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ìœ„í•œ ë©”ëª¨ë¦¬ ê´€ë¦¬ì - LangGraph í‘œì¤€ ì¤€ìˆ˜
"""

import asyncio
import json
import time
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from langchain_core.messages import BaseMessage, HumanMessage

# count_tokens_approximately ëŒ€ì²´
try:
    from langchain_core.messages.utils import count_tokens_approximately
except ImportError:
    def count_tokens_approximately(messages):
        """ê°„ë‹¨í•œ í† í° ì¹´ìš´íŠ¸ ì¶”ì •"""
        total = 0
        for msg in messages:
            if hasattr(msg, 'content'):
                total += len(str(msg.content)) // 4
        return total

logger = logging.getLogger(__name__)


def log_step(step_name: str, status: str, message: str):
    """ë¡œê¹… í—¬í¼ í•¨ìˆ˜"""
    log_message = f"[{step_name}] {status}: {message}"
    if status == "ERROR":
        logger.error(log_message)
    elif status == "WARNING":
        logger.warning(log_message)
    else:
        logger.info(log_message)


def log_performance(operation: str, duration: float, details: str = ""):
    """ì„±ëŠ¥ ë¡œê¹… í—¬í¼ í•¨ìˆ˜"""
    logger.info(f"[PERF] {operation}: {duration:.2f}ms {details}")


# LangGraph í‘œì¤€ ë©”ëª¨ë¦¬ ë„êµ¬
try:
    from langgraph.checkpoint.postgres import PostgresSaver
    LANGRAPH_AVAILABLE = True
except ImportError:
    LANGRAPH_AVAILABLE = False
    class PostgresSaver:
        pass


# =============================================================================
# ğŸ§  DART ë©”ëª¨ë¦¬ ê´€ë¦¬ì - LangGraph í‘œì¤€ ê¸°ë°˜
# =============================================================================

class DartMemoryManager:
    """LangGraph í‘œì¤€ì„ ì¤€ìˆ˜í•˜ëŠ” ë©”ëª¨ë¦¬ ê´€ë¦¬ì"""
    
    def __init__(self, checkpointer, store):
        """
        Args:
            checkpointer: Short-term memory (thread-level persistence)
            store: Long-term memory (user/app-level data)
        """
        self.checkpointer = checkpointer
        self.store = store
        
        # í† í° ì œí•œ ì„¤ì •
        self.token_limits = {
            "master": 10000,
            "financial": 15000,
            "governance": 10000,
            "document": 20000,
            "others": 8000
        }
        
        log_step("DartMemoryManager ì´ˆê¸°í™”", "SUCCESS", "ì²´í¬í¬ì¸í„°ì™€ Store ì—°ê²° ì™„ë£Œ")
    
    # =============================================================================
    # ğŸ§  Short-term Memory - ì²´í¬í¬ì¸í„° í™œìš©
    # =============================================================================
    
    def get_messages(self, thread_id: str) -> List[BaseMessage]:
        """ëŒ€í™” ë©”ì‹œì§€ ì¡°íšŒ"""
        try:
            # ì²´í¬í¬ì¸í„°ì—ì„œ ì§ì ‘ ì¡°íšŒ (í‘œì¤€ ë°©ì‹)
            from langgraph.checkpoint.base import empty_checkpoint
            
            config = {"configurable": {"thread_id": thread_id}}
            checkpoint = self.checkpointer.get(config)
            
            if checkpoint:
                return checkpoint.get("channel_values", {}).get("messages", [])
            return []
            
        except Exception as e:
            log_step("ë©”ì‹œì§€ ì¡°íšŒ", "ERROR", f"ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    async def intelligent_trim_messages(self, messages: List[BaseMessage], 
                                      agent_type: str, max_tokens: Optional[int] = None) -> List[BaseMessage]:
        """ë©”ì‹œì§€ íŠ¸ë¦¼ - ì¤‘ìš”ë„ ê¸°ë°˜"""
        if max_tokens is None:
            max_tokens = self.get_token_limit(agent_type)
        try:
            from langchain_core.messages import ToolMessage as LCToolMessage
            
            current_tokens = count_tokens_approximately(messages)
            
            if current_tokens <= max_tokens:
                return messages
            
            # ì¤‘ìš”ë„ ê¸°ë°˜ ë©”ì‹œì§€ ë¶„ë¥˜
            important_messages = []
            tool_messages = []
            regular_messages = []
            
            for i, message in enumerate(messages):
                # ë„êµ¬ í˜¸ì¶œ/ê²°ê³¼ëŠ” ìµœìš°ì„  ë³´ì¡´
                if hasattr(message, 'tool_calls') and message.tool_calls:
                    important_messages.append(message)
                elif isinstance(message, LCToolMessage):
                    important_messages.append(message)
                elif "ë¶„ì„" in str(message.content) or "ê²°ê³¼" in str(message.content):
                    tool_messages.append(message)
                else:
                    regular_messages.append(message)
            
            # ì¤‘ìš” ë©”ì‹œì§€ ìš°ì„  ë³´ì¡´
            trimmed = []
            remaining_tokens = max_tokens
            
            for msg in important_messages:
                msg_tokens = count_tokens_approximately([msg])
                if msg_tokens <= remaining_tokens:
                    trimmed.append(msg)
                    remaining_tokens -= msg_tokens
            
            for msg in tool_messages:
                msg_tokens = count_tokens_approximately([msg])
                if msg_tokens <= remaining_tokens:
                    trimmed.append(msg)
                    remaining_tokens -= msg_tokens
            
            for msg in reversed(regular_messages):
                msg_tokens = count_tokens_approximately([msg])
                if msg_tokens <= remaining_tokens:
                    trimmed.insert(len(important_messages) + len([m for m in trimmed if m in tool_messages]), msg)
                    remaining_tokens -= msg_tokens
            
            log_step("ë©”ì‹œì§€ íŠ¸ë¦¼", "SUCCESS", f"ì›ë³¸: {len(messages)}ê°œ â†’ {len(trimmed)}ê°œ")
            return trimmed
            
        except Exception as e:
            log_step("ë©”ì‹œì§€ íŠ¸ë¦¼", "ERROR", f"ì˜¤ë¥˜: {e}")
            return messages[-10:] if len(messages) > 10 else messages
    
    async def delete_messages(self, messages: List[BaseMessage], 
                            indices: List[int]) -> List[BaseMessage]:
        """ë©”ì‹œì§€ ì‚­ì œ"""
        try:
            return [msg for i, msg in enumerate(messages) if i not in indices]
        except Exception as e:
            log_step("ë©”ì‹œì§€ ì‚­ì œ", "ERROR", f"ì˜¤ë¥˜: {e}")
            return messages
    
    async def summarize_messages(self, messages: List[BaseMessage], llm) -> str:
        """ë©”ì‹œì§€ ìš”ì•½"""
        try:
            if not messages:
                return "ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
            
            summary_prompt = f"""ë‹¤ìŒ ëŒ€í™”ë¥¼ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”:
            
{chr(10).join([f"- {msg.content}" for msg in messages if hasattr(msg, 'content')])}

ìš”ì•½:"""
            
            response = await llm.ainvoke([HumanMessage(content=summary_prompt)])
            return response.content if hasattr(response, "content") else str(response)
            
        except Exception as e:
            log_step("ë©”ì‹œì§€ ìš”ì•½", "ERROR", f"ì˜¤ë¥˜: {e}")
            return "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"
    
    # =============================================================================
    # ğŸ§  Long-term Memory - Store API í™œìš©
    # =============================================================================
    
    async def save_user_data(self, user_id: str, data_type: str, data: Dict[str, Any]) -> None:
        """ì‚¬ìš©ìë³„ ë°ì´í„° ì €ì¥"""
        try:
            if not self.store:
                log_step("ì‚¬ìš©ì ë°ì´í„° ì €ì¥", "WARNING", "Storeê°€ ì—†ìŒ")
                return
            
            namespace = ("user", user_id)
            await self.store.aput(namespace, data_type, data)
            log_step("ì‚¬ìš©ì ë°ì´í„° ì €ì¥", "SUCCESS", f"user_id: {user_id}, type: {data_type}")
            
        except Exception as e:
            log_step("ì‚¬ìš©ì ë°ì´í„° ì €ì¥", "ERROR", f"ì˜¤ë¥˜: {e}")
    
    async def get_user_data(self, user_id: str, data_type: str) -> Dict[str, Any]:
        """ì‚¬ìš©ìë³„ ë°ì´í„° ì¡°íšŒ"""
        try:
            if not self.store:
                return {}
            
            namespace = ("user", user_id)
            result = await self.store.aget(namespace, data_type)
            return result if result else {}
            
        except Exception as e:
            log_step("ì‚¬ìš©ì ë°ì´í„° ì¡°íšŒ", "ERROR", f"ì˜¤ë¥˜: {e}")
            return {}
    
    async def save_tool_result(self, thread_id: str, agent_type: str, 
                              tool_name: str, tool_result: str) -> None:
        """ë„êµ¬ ê²°ê³¼ ì €ì¥"""
        try:
            if not self.store:
                return
            
            namespace = ("session", thread_id)
            key = f"tool_{agent_type}_{tool_name}_{int(time.time())}"
            data = {
                "agent_type": agent_type,
                "tool_name": tool_name,
                "result": tool_result[:500],
                "timestamp": datetime.now().isoformat()
            }
            await self.store.aput(namespace, key, data)
            
        except Exception as e:
            log_step("ë„êµ¬ ê²°ê³¼ ì €ì¥", "ERROR", f"ì˜¤ë¥˜: {e}")
    
    async def save_analysis_result(self, thread_id: str, corp_code: str, 
                                  analysis_result: Dict[str, Any]) -> None:
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        try:
            if not self.store:
                return
            
            namespace = ("analysis", thread_id)
            key = f"{corp_code}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            await self.store.aput(namespace, key, analysis_result)
            
        except Exception as e:
            log_step("ë¶„ì„ ê²°ê³¼ ì €ì¥", "ERROR", f"ì˜¤ë¥˜: {e}")
    
    async def get_previous_analysis(self, thread_id: str, corp_code: Optional[str] = None) -> List[Dict[str, Any]]:
        """ì´ì „ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        try:
            if not self.store:
                return []
            
            namespace = ("analysis", thread_id)
            results = await self.store.asearch(namespace)
            
            if corp_code and corp_code != "any":
                results = [r for r in results if corp_code in r.get("key", "")]
            
            return results[:3]
            
        except Exception as e:
            log_step("ì´ì „ ë¶„ì„ ì¡°íšŒ", "ERROR", f"ì˜¤ë¥˜: {e}")
            return []
    
    async def save_context_memory(self, thread_id: str, context_key: str, 
                                 context_data: Dict[str, Any]) -> None:
        """ì»¨í…ìŠ¤íŠ¸ ë©”ëª¨ë¦¬ ì €ì¥"""
        try:
            if not self.store:
                return
            
            namespace = ("context", thread_id)
            await self.store.aput(namespace, context_key, context_data)
            
        except Exception as e:
            log_step("ì»¨í…ìŠ¤íŠ¸ ë©”ëª¨ë¦¬ ì €ì¥", "ERROR", f"ì˜¤ë¥˜: {e}")
    
    async def search_user_data(self, user_id: str, query: str) -> List[Dict[str, Any]]:
        """ì‚¬ìš©ì ë°ì´í„° ê²€ìƒ‰"""
        try:
            if not self.store:
                return []
            
            namespace = ("user", user_id)
            results = await self.store.asearch(namespace, query)
            return results
            
        except Exception as e:
            log_step("ì‚¬ìš©ì ë°ì´í„° ê²€ìƒ‰", "ERROR", f"ì˜¤ë¥˜: {e}")
            return []
    
    async def list_user_data_keys(self, user_id: str) -> List[str]:
        """ì‚¬ìš©ì ë°ì´í„° í‚¤ ëª©ë¡"""
        try:
            if not self.store:
                return []
            
            namespace = ("user", user_id)
            keys = await self.store.alist(namespace)
            return keys
            
        except Exception as e:
            log_step("í‚¤ ëª©ë¡ ì¡°íšŒ", "ERROR", f"ì˜¤ë¥˜: {e}")
            return []
    
    async def delete_user_data(self, user_id: str, data_type: str) -> bool:
        """ì‚¬ìš©ì ë°ì´í„° ì‚­ì œ"""
        try:
            if not self.store:
                return False
            
            namespace = ("user", user_id)
            await self.store.adelete(namespace, data_type)
            log_step("ì‚¬ìš©ì ë°ì´í„° ì‚­ì œ", "SUCCESS", f"user_id: {user_id}, type: {data_type}")
            return True
            
        except Exception as e:
            log_step("ì‚¬ìš©ì ë°ì´í„° ì‚­ì œ", "ERROR", f"ì˜¤ë¥˜: {e}")
            return False
    
    async def save_app_data(self, data_type: str, data: Dict[str, Any]) -> None:
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ë°ì´í„° ì €ì¥"""
        try:
            if not self.store:
                return
            
            namespace = ("app", "global")
            await self.store.aput(namespace, data_type, data)
            log_step("ì•± ë°ì´í„° ì €ì¥", "SUCCESS", f"type: {data_type}")
            
        except Exception as e:
            log_step("ì•± ë°ì´í„° ì €ì¥", "ERROR", f"ì˜¤ë¥˜: {e}")
    
    async def get_app_data(self, data_type: str) -> Dict[str, Any]:
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ë°ì´í„° ì¡°íšŒ"""
        try:
            if not self.store:
                return {}
            
            namespace = ("app", "global")
            result = await self.store.aget(namespace, data_type)
            return result if result else {}
            
        except Exception as e:
            log_step("ì•± ë°ì´í„° ì¡°íšŒ", "ERROR", f"ì˜¤ë¥˜: {e}")
            return {}
    
    # =============================================================================
    # ğŸ§  í† í° ê´€ë¦¬
    # =============================================================================
    
    async def update_token_usage(self, thread_id: str, agent_type: str, 
                                response_tokens: int = 0):
        """í† í° ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸ - Storeì— ì €ì¥"""
        try:
            if not self.store:
                return
            
            namespace = ("session", thread_id)
            key = f"token_usage_{agent_type}"
            
            # ê¸°ì¡´ ì‚¬ìš©ëŸ‰ ì¡°íšŒ
            existing = await self.store.aget(namespace, key) or {"total": 0}
            existing["total"] = existing.get("total", 0) + response_tokens
            existing["last_updated"] = datetime.now().isoformat()
            
            # ì—…ë°ì´íŠ¸
            await self.store.aput(namespace, key, existing)
            
            # ê²½ê³  ë¡œê¹…
            limit = self.token_limits.get(agent_type, self.token_limits["others"])
            if existing["total"] > limit * 0.8:
                log_step("í† í° ê²½ê³ ", "WARNING", f"{agent_type}: {existing['total']}/{limit}")
            
        except Exception as e:
            log_step("í† í° ì—…ë°ì´íŠ¸", "ERROR", f"ì˜¤ë¥˜: {e}")
    
    def get_token_limit(self, agent_type: str) -> int:
        """ì—ì´ì „íŠ¸ë³„ í† í° ì œí•œ"""
        return self.token_limits.get(agent_type.lower(), self.token_limits["others"])