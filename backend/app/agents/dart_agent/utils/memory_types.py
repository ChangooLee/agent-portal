"""
memory_types.py
DART ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ë°ì´í„° êµ¬ì¡° ì •ì˜
"""

from typing import TypedDict, List, Dict, Any, Optional
from langchain_core.messages import BaseMessage
from datetime import datetime
from enum import Enum


# =============================================================================
# ğŸ§  ë©”ëª¨ë¦¬ ê´€ë¦¬ìš© ì—´ê±°í˜•
# =============================================================================

class MemoryType(Enum):
    """ë©”ëª¨ë¦¬ íƒ€ì…"""
    CONVERSATION = "conversation"
    ANALYSIS_RESULT = "analysis_result"
    USER_PREFERENCE = "user_preference"
    CONTEXT_MEMORY = "context_memory"
    TOKEN_USAGE = "token_usage"


class MessagePriority(Enum):
    """ë©”ì‹œì§€ ì¤‘ìš”ë„"""
    CRITICAL = 1.0      # ë„êµ¬ í˜¸ì¶œ/ê²°ê³¼
    HIGH = 0.8          # ë¶„ì„ ê´€ë ¨ ë©”ì‹œì§€
    MEDIUM = 0.5        # ì¼ë°˜ ë©”ì‹œì§€
    LOW = 0.2           # ë¶€ê°€ ì •ë³´


# =============================================================================
# ğŸ§  ë©”ëª¨ë¦¬ ê´€ë¦¬ìš© State êµ¬ì¡°
# =============================================================================

class MemoryState(TypedDict):
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ í™•ì¥ëœ State"""
    # ê¸°ë³¸ ë©”ì‹œì§€
    messages: List[BaseMessage]
    
    # ë©”ëª¨ë¦¬ ê´€ë¦¬
    conversation_summary: Optional[str]  # ëŒ€í™” ìš”ì•½
    analysis_cache: Dict[str, Any]  # ë¶„ì„ ê²°ê³¼ ìºì‹œ
    user_preferences: Dict[str, Any]  # ì‚¬ìš©ì ì„ í˜¸ë„
    context_memory: Dict[str, Any]  # ì»¨í…ìŠ¤íŠ¸ ë©”ëª¨ë¦¬
    
    # í† í° ê´€ë¦¬
    token_usage: Dict[str, int]  # ì—ì´ì „íŠ¸ë³„ í† í° ì‚¬ìš©ëŸ‰
    context_priority: Dict[str, float]  # ì»¨í…ìŠ¤íŠ¸ ì¤‘ìš”ë„
    
    # ë©”íƒ€ë°ì´í„°
    thread_id: str
    session_id: str
    last_updated: datetime
    memory_version: int


class DartAnalysisState(MemoryState):
    """DART ë¶„ì„ì„ ìœ„í•œ íŠ¹í™”ëœ State"""
    # ê¸°ì¡´ AnalysisContext í•„ë“œë“¤
    corp_code: str
    corp_name: str
    user_question: str
    scope: str
    domain: str
    depth: str
    
    # ë¶„ì„ ê²°ê³¼
    agent_results: List[Dict[str, Any]]
    integrated_analysis: Optional[str]
    
    # ë©”ëª¨ë¦¬ ê´€ë¦¬
    previous_analyses: List[Dict[str, Any]]  # ì´ì „ ë¶„ì„ ê²°ê³¼ë“¤
    company_metadata: Dict[str, Any]  # ê¸°ì—…ë³„ ë©”íƒ€ë°ì´í„°
    analysis_patterns: Dict[str, Any]  # ë¶„ì„ íŒ¨í„´


# =============================================================================
# ğŸ§  ë©”ëª¨ë¦¬ ê´€ë¦¬ìš© ë°ì´í„° í´ë˜ìŠ¤
# =============================================================================

class MemoryEntry:
    """ë©”ëª¨ë¦¬ ì—”íŠ¸ë¦¬"""
    def __init__(self, key: str, value: Any, memory_type: MemoryType, 
                 priority: float = 0.5, created_at: datetime = None):
        self.key = key
        self.value = value
        self.memory_type = memory_type
        self.priority = priority
        self.created_at = created_at or datetime.now()
        self.last_accessed = datetime.now()
        self.access_count = 0
    
    def access(self):
        """ë©”ëª¨ë¦¬ ì ‘ê·¼ ê¸°ë¡"""
        self.last_accessed = datetime.now()
        self.access_count += 1
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "key": self.key,
            "value": self.value,
            "memory_type": self.memory_type.value,
            "priority": self.priority,
            "created_at": self.created_at.isoformat(),
            "last_accessed": self.last_accessed.isoformat(),
            "access_count": self.access_count
        }


class TokenUsage:
    """í† í° ì‚¬ìš©ëŸ‰ ì¶”ì """
    def __init__(self, agent_type: str):
        self.agent_type = agent_type
        self.total_tokens = 0
        self.message_tokens = 0
        self.tool_tokens = 0
        self.response_tokens = 0
        self.last_updated = datetime.now()
    
    def add_usage(self, message_tokens: int = 0, tool_tokens: int = 0, 
                  response_tokens: int = 0):
        """í† í° ì‚¬ìš©ëŸ‰ ì¶”ê°€"""
        self.message_tokens += message_tokens
        self.tool_tokens += tool_tokens
        self.response_tokens += response_tokens
        self.total_tokens = self.message_tokens + self.tool_tokens + self.response_tokens
        self.last_updated = datetime.now()
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "agent_type": self.agent_type,
            "total_tokens": self.total_tokens,
            "message_tokens": self.message_tokens,
            "tool_tokens": self.tool_tokens,
            "response_tokens": self.response_tokens,
            "last_updated": self.last_updated.isoformat()
        }


class AnalysisCache:
    """ë¶„ì„ ê²°ê³¼ ìºì‹œ"""
    def __init__(self, corp_code: str, analysis_type: str):
        self.corp_code = corp_code
        self.analysis_type = analysis_type
        self.results = {}
        self.created_at = datetime.now()
        self.last_accessed = datetime.now()
        self.hit_count = 0
    
    def get(self, key: str) -> Any:
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
        self.last_accessed = datetime.now()
        if key in self.results:
            self.hit_count += 1
            return self.results[key]
        return None
    
    def set(self, key: str, value: Any):
        """ìºì‹œì— ê°’ ì €ì¥"""
        self.results[key] = value
        self.last_accessed = datetime.now()
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "corp_code": self.corp_code,
            "analysis_type": self.analysis_type,
            "results": self.results,
            "created_at": self.created_at.isoformat(),
            "last_accessed": self.last_accessed.isoformat(),
            "hit_count": self.hit_count
        }


# =============================================================================
# ğŸ§  ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì •
# =============================================================================

class MemoryConfig:
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì •"""
    
    # ì—ì´ì „íŠ¸ë³„ í† í° ì œí•œ
    TOKEN_LIMITS = {
        "master": 10000,      # ë§ˆìŠ¤í„° ì—ì´ì „íŠ¸
        "financial": 15000,   # ì¬ë¬´ ë¶„ì„
        "governance": 10000,  # ì§€ë°°êµ¬ì¡° ë¶„ì„
        "document": 20000,    # ë¬¸ì„œ ë¶„ì„ (ê°€ì¥ ë§ì€ í† í° í•„ìš”)
        "capital_change": 8000,
        "debt_funding": 8000,
        "business_structure": 8000,
        "overseas_business": 8000,
        "legal_risk": 8000,
        "executive_audit": 8000,
        "others": 8000        # ê¸°íƒ€ ì—ì´ì „íŠ¸ë“¤
    }
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬ ì„¤ì •
    MAX_CACHE_SIZE = 1000     # ìµœëŒ€ ìºì‹œ í¬ê¸°
    MAX_ANALYSIS_HISTORY = 50  # ìµœëŒ€ ë¶„ì„ íˆìŠ¤í† ë¦¬
    CACHE_TTL_HOURS = 24      # ìºì‹œ TTL (ì‹œê°„)
    
    # í† í° ê´€ë¦¬ ì„¤ì •
    MAX_TOTAL_TOKENS = 65000  # ì „ì²´ ìµœëŒ€ í† í°
    TOKEN_BUFFER = 5000       # í† í° ë²„í¼
    
    @classmethod
    def get_token_limit(cls, agent_type: str) -> int:
        """ì—ì´ì „íŠ¸ íƒ€ì…ë³„ í† í° ì œí•œ ì¡°íšŒ"""
        return cls.TOKEN_LIMITS.get(agent_type.lower(), cls.TOKEN_LIMITS["others"])
    
    @classmethod
    def is_token_within_limit(cls, agent_type: str, current_tokens: int) -> bool:
        """í† í° ì‚¬ìš©ëŸ‰ì´ ì œí•œ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸"""
        limit = cls.get_token_limit(agent_type)
        return current_tokens <= limit