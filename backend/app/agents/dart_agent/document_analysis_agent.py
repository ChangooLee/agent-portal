"""
document_analysis_agent.py
ë¬¸ì„œ ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ ì „ë¬¸ ì—ì´ì „íŠ¸
ì‚¬ì—…ë³´ê³ ì„œ, ë°˜ê¸°ë³´ê³ ì„œ, ë¶„ê¸°ë³´ê³ ì„œì˜ ì›ë³¸ ë¬¸ì„œë¥¼ íŒŒì‹±í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ê¸°ëŠ¥
"""

import time
import re
import json
import uuid
import logging
from typing import Dict, Any, List, Optional, AsyncGenerator
from datetime import datetime
from langchain_core.messages import ToolMessage, SystemMessage

# Agent Portal imports
from .base import DartBaseAgent, LiteLLMAdapter
from .dart_types import (
    AnalysisContext,
    AgentResult,
    RiskLevel,
    AnalysisScope,
    AnalysisDomain,
    AnalysisDepth,
)
from .message_refiner import MessageRefiner
from .mcp_client import MCPTool, get_opendart_mcp_client
from .metrics import start_dart_span, record_counter, inject_context_to_carrier

logger = logging.getLogger(__name__)

def log_step(step_name: str, status: str, message: str):
    logger.info(f"[{step_name}] {status}: {message}")

def log_agent_flow(agent_name: str, action: str, step: int, message: str):
    logger.info(f"[{agent_name}] Step {step} - {action}: {message}")

def observe():
    def decorator(func):
        return func
    return decorator


class DocumentAnalysisAgent(BaseAgent):
    """ë¬¸ì„œ ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ ì „ë¬¸ ì—ì´ì „íŠ¸"""

    def __init__(
        self,
        llm,
        mcp_servers,
        checkpoint_db_path: str = "sqlite/checkpoints_dart_document.db",
    ):
        """DocumentAnalysisAgent ì´ˆê¸°í™”"""
        # mcp_serversë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if isinstance(mcp_servers, dict):
            mcp_servers = [mcp_servers]
        else:
            mcp_servers = mcp_servers

        # BaseAgent ì´ˆê¸°í™”
        super().__init__(
            agent_name="DocumentAnalysisAgent",
            llm=llm,
            mcp_servers=mcp_servers,
            checkpoint_db_path=checkpoint_db_path,
        )

        self.mcp_servers = mcp_servers
        self.agent_domain = "document_analysis"
        self.prompt_builder = PromptBuilder()
        log_step(
            "DocumentAnalysisAgent ì´ˆê¸°í™”",
            "SUCCESS",
            f"MCP ì„œë²„ {len(mcp_servers)}ê°œ ë“±ë¡ ì™„ë£Œ",
        )
        # ë©”ì‹œì§€ ì •ì œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.message_refiner = MessageRefiner()

    async def _filter_tools_for_agent(self, tools):
        """ë¬¸ì„œ ë¶„ì„ì—ì„œ ì‚¬ìš©í•  ë„êµ¬ í•„í„°ë§"""
        filtered_tools = []

        # ë¬¸ì„œ ë¶„ì„ ê´€ë ¨ ë„êµ¬ë§Œ í•„í„°ë§
        target_tools = {
            "get_disclosure_list",  # ê³µì‹œëª©ë¡ (ì ì ˆí•œ ë³´ê³ ì„œ ì°¾ê¸°)
            "get_disclosure_document",  # ê³µì‹œì„œë¥˜ ì›ë³¸ ë‹¤ìš´ë¡œë“œ
            "search_financial_notes",  # ê³µì‹œë¬¸ì„œ ìƒì„¸ë‚´ìš© í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
        }
        
        for tool in tools:
            tool_name = getattr(tool, "name", "")
            if tool_name in target_tools:
                filtered_tools.append(tool)
                log_step("ë„êµ¬ í•„í„°ë§", "SUCCESS", f"DocumentAnalysis ë„êµ¬ ì¶”ê°€: {tool_name}")

        log_step(
            "ë„êµ¬ í•„í„°ë§ ì™„ë£Œ",
            "SUCCESS",
            f"DocumentAnalysisAgentì—ì„œ ì‚¬ìš©í•  ë„êµ¬: {len(filtered_tools)}ê°œ",
        )
        return filtered_tools

    def _create_analysis_prompt(self, context: AnalysisContext) -> str:
        """User Request Prompt ìƒì„± - context ê¸°ë°˜"""
        return self._create_user_request(context)

    @observe()
    async def analyze_document_data(
        self, context: AnalysisContext
    ) -> AsyncGenerator[Dict[str, Any], AgentResult]:
        """ë¬¸ì„œ ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜ - ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° + ìŠ¤íŠ¸ë¦¬ë°"""
        start_time = time.time()

        try:
            # 1ë²ˆ yield: ë¶„ì„ ì‹œì‘
            yield {
                "type": "progress",
                "content": f"{context.corp_name}ì˜ ë¬¸ì„œ ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤...",
            }

            log_agent_flow(
                "DocumentAnalysisAgent",
                "ë¬¸ì„œ ë¶„ì„ ì‹œì‘",
                0,
                f"ê¸°ì—…: {context.corp_name}, ì§ˆë¬¸: {context.user_question[:100]}...",
            )

            # BaseAgent ì´ˆê¸°í™” í™•ì¸
            if not self._initialized:
                yield {"type": "progress", "content": "ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤..."}
                await self.initialize()

            # 2ë²ˆ yield: ë¬¸ì„œ ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì‹œì‘
            yield {
                "type": "progress",
                "content": "ë¬¸ì„œ ë¶„ì„ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤: 1) ë³´ê³ ì„œ ì‹ë³„ â†’ 2) ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ â†’ 3) ë°ì´í„° ì¶”ì¶œ â†’ 4) í‚¤ì›Œë“œ ê²€ìƒ‰",
            }

            # ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
            analysis_prompt = self._create_analysis_prompt(context)

            # LangGraph ì—ì´ì „íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
            final_response = ""
            tools_used = []
            collected_data = {}

            # â˜… ë£¨í”„ ë°”ë¡œ ìœ„ì— ì¶”ê°€: í˜¸ì¶œ ì •ë³´ë¥¼ ì ì‹œ ë³´ê´€
            pending_calls = {}  # tool_call_id -> {"display_name": str, "args": dict, "t0": float}

            async for chunk in self.agent_executor.astream(
                {"messages": [("human", analysis_prompt)]},
                config={
                    "recursion_limit": 100,
                    "configurable": {
                        "thread_id": f"document_analysis_{context.corp_code}_{int(time.time())}"
                    }
                },
            ):
                # LangGraph ì‹¤í–‰ ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²˜ë¦¬
                if "agent" in chunk:
                    # LLMì˜ ì‘ë‹µ (ë„êµ¬ ì„ íƒ ì´ìœ  í¬í•¨)
                    agent_messages = chunk["agent"]["messages"]
                    if agent_messages:
                        agent_message = agent_messages[-1]  # ê°€ì¥ ìµœê·¼ ë©”ì‹œì§€

                        if hasattr(agent_message, "content") and agent_message.content:
                            # LLMì˜ ì‚¬ê³  ê³¼ì • ìŠ¤íŠ¸ë¦¬ë° (ê¸°ì¡´ ìœ ì§€)
                            content = agent_message.content.strip()
                            if content:
                                yield {
                                    "type": "progress",
                                    "content": f"ë¬¸ì„œ ë¶„ì„ ì—ì´ì „íŠ¸ ë¶„ì„: {content}...",
                                }
                                if final_response:
                                    final_response += "\n" + content
                                else:
                                    final_response = content

                        # (í•µì‹¬) ë„êµ¬ í˜¸ì¶œì€ "ì¶œë ¥ ì•ˆ í•˜ê³ " ì €ì¥ë§Œ í•œë‹¤
                        if hasattr(agent_message, "tool_calls") and agent_message.tool_calls:
                            for tool_call in agent_message.tool_calls:
                                tool_name = tool_call.get("name", "ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬")
                                tool_args = tool_call.get("args", {}) or {}
                                # raw_args íŒŒì‹± ì²˜ë¦¬
                                tool_args = self._process_tool_args(tool_args)

                                # í˜ì–´ë§ìš© call_id í™•ë³´
                                tc_id = (
                                    tool_call.get("id")
                                    or tool_call.get("tool_call_id")
                                    or f"{tool_name}-{int(time.time()*1000)}-{uuid.uuid4().hex[:6]}"
                                )

                                display_name = self.message_refiner.refine(tool_name)
                                # í˜¸ì¶œ ë¡œê·¸ëŠ” ì§€ê¸ˆ ë‚´ë³´ë‚´ì§€ ì•ŠìŒ! (ë³‘ë ¬ì´ë¼ ìˆœì„œ ê¹¨ì§€ë¯€ë¡œ)
                                pending_calls[tc_id] = {
                                    "display_name": display_name,
                                    "args": tool_args,
                                    "t0": time.perf_counter(),
                                }

                elif "tools" in chunk:
                    # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬
                    tool_messages = chunk["tools"]["messages"]
                    for tool_message in tool_messages:
                        tool_name = getattr(tool_message, "name", "ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬")
                        tools_used.append(tool_name)

                        # ì‘ë‹µì— ë‹¬ë¦° tool_call_idë¡œ pendingê³¼ ë§¤ì¹­
                        tc_id = getattr(tool_message, "tool_call_id", None)
                        if tc_id and tc_id in pending_calls:
                            info = pending_calls.pop(tc_id)
                            display_name = info["display_name"]
                            tool_args = info["args"]

                            # ì‚¬ìš©ì ì¹œí™”ì  ì•¡ì…˜ ë©”ì‹œì§€ (ì •ì  ë§¤í•‘, ì¦‰ì‹œ ë°˜í™˜)
                            action_msg = self.message_refiner.get_action_message(tool_name)
                            yield {"type": "progress", "content": action_msg}

                            yield {
                                "type": "tool_call",
                                "tool_name": display_name,
                                "tool_args": tool_args,
                            }

                        else:
                            # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì´ë¦„ë§Œ ì •ì œ
                            display_name = self.message_refiner.refine(tool_name)

                        # ì´ì–´ì„œ 'ì‘ë‹µ ë¡œê·¸' ì¶œë ¥
                        if hasattr(tool_message, "content"):
                            # DART Transformer í™œìš©
                            from agent.dart_agent.dart_transformer import transform_dart_result
                            extracted_text = transform_dart_result(tool_name, tool_message.content)
                            collected_data[tool_name] = extracted_text
                            yield {
                                "type": "tool_result",
                                "content": extracted_text,
                                "tool_name": display_name,
                            }

            # ğŸ”¥ AgentResultì— LLMì˜ ì‹¤ì œ ë¶„ì„ ê²°ê³¼ë¥¼ ë‹´ì•„ì„œ ë°˜í™˜
            agent_result = AgentResult(
                agent_name=self.agent_name,
                analysis_type="document_analysis_streaming",
                risk_level=RiskLevel.LOW,
                key_findings=[final_response] if final_response else ["ë¬¸ì„œ ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ ì™„ë£Œ"],
                supporting_data={
                    "llm_response": final_response,
                    "raw_document_data": collected_data,
                    "execution_time": time.time() - start_time,
                },
                recommendations=[],
                execution_time=time.time() - start_time,
                tools_used=list(set(tools_used)),
            )
            
            # ìµœì¢… ê²°ê³¼ yield
            yield agent_result
            return
            
        except Exception as e:
            log_step("ë¬¸ì„œ ë¶„ì„ ì˜¤ë¥˜", "ERROR", f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback

            log_step("ë¬¸ì„œ ë¶„ì„ ì˜¤ë¥˜", "ERROR", f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")

            # ì—ëŸ¬ yield
            yield {"type": "error", "content": f"ë¬¸ì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

            agent_result = AgentResult(
                agent_name=self.agent_name,
                analysis_type="error",
                risk_level=RiskLevel.HIGH,
                key_findings=[f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}"],
                supporting_data={"error": str(e)},
                recommendations=["ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ í•„ìš”"],
                execution_time=time.time() - start_time,
                tools_used=[],
            )

            yield agent_result
            return

    @observe()
    def _extract_text_from_content(self, content) -> str:
        """ë‹¤ì–‘í•œ content íƒ€ì…ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if isinstance(content, str):
            return content
        elif isinstance(content, list):
            # TextContent ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
            texts = []
            for item in content:
                if hasattr(item, "text"):
                    texts.append(item.text)
                elif hasattr(item, "content"):
                    texts.append(str(item.content))
                else:
                    texts.append(str(item))
            return "".join(texts)
        elif hasattr(content, "text"):
            # ë‹¨ì¼ TextContent ê°ì²´
            return content.text
        else:
            return str(content)
            
    def _setup_agent(self):
        """ì—ì´ì „íŠ¸ ì„¤ì •"""
        try:
            log_step(f"{self.agent_name} ì—ì´ì „íŠ¸ ì„¤ì •", "START", "create_agent ìƒì„± ì¤‘...")
                        
            # ë„ë©”ì¸ë³„ í”„ë¡¬í”„íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ì§ì ‘ ì „ë‹¬
            domain_prompt = self._create_domain_prompt()
            
            # create_agentë¡œ ì—ì´ì „íŠ¸ ìƒì„± (promptì— ë¬¸ìì—´ ì§ì ‘ ì „ë‹¬)
            self.agent = create_agent(
                model=self.llm_with_tools,
                tools=self.filtered_tools,
                prompt=SystemMessage(content=domain_prompt),
                checkpointer=self.checkpointer
            )
            
            log_step(f"{self.agent_name} ì—ì´ì „íŠ¸ ì„¤ì •", "SUCCESS", "create_agent ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            log_step(f"{self.agent_name} ì—ì´ì „íŠ¸ ì„¤ì •", "FAIL", f"ì—ì´ì „íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
            raise
